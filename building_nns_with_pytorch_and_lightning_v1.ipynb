{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "warming-trinidad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m TensorDataset, DataLoader \u001b[39m# these are needed for the training data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m \u001b[39m## matplotlib allows us to draw graphs.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m \u001b[39m## seaborn makes it easier to draw nice-looking graphs.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m                                 \u001b[39m# getting different results.\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import torch # torch will allow us to create tensors.\n",
    "import torch.nn as nn # torch.nn allows us to create a neural network.\n",
    "import torch.nn.functional as F # nn.functional give us access to the activation and loss functions.\n",
    "from torch.optim import SGD # optim contains many optimizers. Here, we're using SGD, stochastic gradient descent.\n",
    "\n",
    "import lightning as L # lightning has tons of cool tools that make neural networks easier\n",
    "from torch.utils.data import TensorDataset, DataLoader # these are needed for the training data\n",
    "\n",
    "import matplotlib.pyplot as plt ## matplotlib allows us to draw graphs.\n",
    "import seaborn as sns ## seaborn makes it easier to draw nice-looking graphs.\n",
    "                                # getting different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "square-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a neural network class by creating a class that inherits from LightningModule\n",
    "class BasicLightning(L.LightningModule):\n",
    "\n",
    "\n",
    "    def __init__(self): # __init__() is the class constructor function, and we use it to initialize the weights and biases.\n",
    "        \n",
    "        super().__init__() # initialize an instance of the parent class, L.LightningModule.\n",
    "        \n",
    "        ## Now create the weights and biases that we need for our neural network.\n",
    "        ## Each weight or bias is an nn.Parameter, which gives us the option to optimize the parameter by setting\n",
    "        ## requires_grad, which is short for \"requires gradient\", to True. Since we don't need to optimize any of these\n",
    "        ## parameters now, we set requires_grad=False.\n",
    "        ##\n",
    "        ## NOTE: Because our neural network is already fit to the data, we will input specific values\n",
    "        ## for each weight and bias. In contrast, if we had not already fit the neural network to the data,\n",
    "        ## we might start with a random initalization of the weights and biases.\n",
    "        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n",
    "        self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n",
    "        self.w01 = nn.Parameter(torch.tensor(-40.8), requires_grad=False)\n",
    "        \n",
    "        self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n",
    "        self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n",
    "\n",
    "        self.final_bias = nn.Parameter(torch.tensor(-16.), requires_grad=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, input): ## forward() takes an input value and runs it though the neural network \n",
    "                              ## illustrated at the top of this notebook. \n",
    "        \n",
    "        ## the next three lines implement the top of the neural network (using the top node in the hidden layer).\n",
    "        input_to_top_relu = input * self.w00 + self.b00\n",
    "        top_relu_output = F.relu(input_to_top_relu)\n",
    "        scaled_top_relu_output = top_relu_output * self.w01\n",
    "        \n",
    "        ## the next three lines implement the bottom of the neural network (using the bottom node in the hidden layer).\n",
    "        input_to_bottom_relu = input * self.w10 + self.b10\n",
    "        bottom_relu_output = F.relu(input_to_bottom_relu)\n",
    "        scaled_bottom_relu_output = bottom_relu_output * self.w11\n",
    "        \n",
    "        ## here, we combine both the top and bottom nodes from the hidden layer with the final bias.\n",
    "        input_to_final_relu = (scaled_top_relu_output \n",
    "                               + scaled_bottom_relu_output \n",
    "                               + self.final_bias)\n",
    "        \n",
    "        output = F.relu(input_to_final_relu)\n",
    "    \n",
    "        return output # output is the predicted effectiveness for a drug dose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-retrieval",
   "metadata": {},
   "source": [
    "Once we have created the class that defines the neural network, we can create an actual neural network and print out its parameters, just to make sure things are what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fifth-driver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w00 tensor(1.7000)\n",
      "b00 tensor(-0.8500)\n",
      "w01 tensor(-40.8000)\n",
      "w10 tensor(12.6000)\n",
      "b10 tensor(0.)\n",
      "w11 tensor(2.7000)\n",
      "final_bias tensor(-16.)\n"
     ]
    }
   ],
   "source": [
    "## create the neural network. \n",
    "model = BasicLightning()\n",
    "\n",
    "## print out the name and value for each parameter\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "induced-receiver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
       "        0.9000, 1.0000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create the different doses we want to run through the neural network.\n",
    "## torch.linspace() creates the sequence of numbers between, and including, 0 and 1.\n",
    "input_doses = torch.linspace(start=0, end=1, steps=11)\n",
    "\n",
    "# now print out the doses to make sure they are what we expect...\n",
    "input_doses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-cylinder",
   "metadata": {},
   "source": [
    "Now that we have `input_doses`, let's run them through the neural network and graph the output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "understood-confusion",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m output_values \u001b[39m=\u001b[39m model(input_doses)\n\u001b[1;32m      7\u001b[0m \u001b[39m## Now draw a graph that shows the effectiveness for each dose.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m##\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m## First, set the style for seaborn so that the graph looks cool.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m sns\u001b[39m.\u001b[39mset(style\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwhitegrid\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39m## create the graph (you might not see it at this point, but you will after we save it as a PDF).\u001b[39;00m\n\u001b[1;32m     13\u001b[0m sns\u001b[39m.\u001b[39mlineplot(x\u001b[39m=\u001b[39minput_doses, \n\u001b[1;32m     14\u001b[0m              y\u001b[39m=\u001b[39moutput_values, \n\u001b[1;32m     15\u001b[0m              color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     16\u001b[0m              linewidth\u001b[39m=\u001b[39m\u001b[39m2.5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "## create the neural network. \n",
    "model = BasicLightning() \n",
    "\n",
    "## now run the different doses through the neural network.\n",
    "output_values = model(input_doses)\n",
    "\n",
    "## Now draw a graph that shows the effectiveness for each dose.\n",
    "##\n",
    "## First, set the style for seaborn so that the graph looks cool.\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "## create the graph (you might not see it at this point, but you will after we save it as a PDF).\n",
    "sns.lineplot(x=input_doses, \n",
    "             y=output_values, \n",
    "             color='green', \n",
    "             linewidth=2.5)\n",
    "\n",
    "## now label the y- and x-axes.\n",
    "plt.ylabel('Effectiveness')\n",
    "plt.xlabel('Dose')\n",
    "\n",
    "## optionally, save the graph as a PDF.\n",
    "# plt.savefig('BasicLightning.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a neural network class that we can train by creating a class that inherits from LightningModule\n",
    "##\n",
    "## NOTE: This new class, BasicLightningTrain, contains two new methods for training:\n",
    "##\n",
    "## training_step() - This method takes care of 4 things:\n",
    "##      a) calculates the loss for an epoch\n",
    "##      b) resets the gradients\n",
    "##      c) backpropagation\n",
    "##      d) updates the parameters\n",
    "## configure_optimizers() - defines the method we will use to optimize the model\n",
    "class BasicLightningTrain(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):  # __init__() is the class constructor function, and we use it to initialize the weights and biases.\n",
    "\n",
    "        ## NOTE: The code for __init__ () is the same as before except we now have a learning rate parameter (for\n",
    "        ##       gradient descent) and we modified final_bias in two ways:\n",
    "        ##           1) we set the value of the tensor to 0, and\n",
    "        ##           2) we set \"requires_grad=True\".\n",
    "\n",
    "        super().__init__()  # initialize an instance of the parent class, LightningModule.\n",
    "\n",
    "        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n",
    "        self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n",
    "        self.w01 = nn.Parameter(torch.tensor(-40.8), requires_grad=False)\n",
    "\n",
    "        self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n",
    "        self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n",
    "\n",
    "        ## We want to modify final_bias to demonstrate how to optimize it with backpropagation.\n",
    "        ## NOTE: The optimal value for final_bias is -16...\n",
    "        #         self.final_bias = nn.Parameter(torch.tensor(-16.), requires_grad=False)\n",
    "        ## ...so we set it to 0 and tell Pytorch that it now needs to calculate the gradient for this parameter.\n",
    "        self.final_bias = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n",
    "\n",
    "        self.learning_rate = 0.01  ## this is for gradient descent. NOTE: we will improve this value later, so, technically\n",
    "        ## this is just a placeholder until then. In other words, we could put any value here\n",
    "        ## because later we will replace it with the improved value.\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        ## forward() is the exact same as before\n",
    "\n",
    "        input_to_top_relu = input * self.w00 + self.b00\n",
    "        top_relu_output = F.relu(input_to_top_relu)\n",
    "        scaled_top_relu_output = top_relu_output * self.w01\n",
    "\n",
    "        input_to_bottom_relu = input * self.w10 + self.b10\n",
    "        bottom_relu_output = F.relu(input_to_bottom_relu)\n",
    "        scaled_bottom_relu_output = bottom_relu_output * self.w11\n",
    "\n",
    "        input_to_final_relu = (\n",
    "            scaled_top_relu_output + scaled_bottom_relu_output + self.final_bias\n",
    "        )\n",
    "\n",
    "        output = F.relu(input_to_final_relu)\n",
    "\n",
    "        return output  # output is the predicted effectiveness for a drug dose.\n",
    "\n",
    "    def configure_optimizers(\n",
    "        self,\n",
    "    ):  # this configures the optimizer we want to use for backpropagation.\n",
    "        return SGD(\n",
    "            self.parameters(), lr=self.learning_rate\n",
    "        )  # NOTE: We set the learning rate (lr) to our new variable\n",
    "        # self.learning_rate\n",
    "\n",
    "    def training_step(self, batch, batch_idx):  # take a step during gradient descent.\n",
    "\n",
    "        ## NOTE: When training_step() is called it calculates the loss with the code below...\n",
    "        input_i, label_i = batch  # collect input\n",
    "        output_i = self.forward(input_i)  # run input through the neural network\n",
    "        loss = (output_i - label_i) ** 2  ## loss = squared residual\n",
    "\n",
    "        ##...before calling (internally and behind the scenes)...\n",
    "        ## optimizer.zero_grad() # to clear gradients\n",
    "        ## loss.backward() # to do the backpropagation\n",
    "        ## optimizer.step() # to update the parameters\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-wisdom",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BasicLightningTrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## create the neural network. \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m BasicLightningTrain() \n\u001b[1;32m      4\u001b[0m \u001b[39m## now run the different doses through the neural network.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m output_values \u001b[39m=\u001b[39m model(input_doses)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BasicLightningTrain' is not defined"
     ]
    }
   ],
   "source": [
    "## create the neural network. \n",
    "model = BasicLightningTrain() \n",
    "\n",
    "## now run the different doses through the neural network.\n",
    "output_values = model(input_doses)\n",
    "\n",
    "## Now draw a graph that shows the effectiveness for each dose.\n",
    "##\n",
    "## set the style for seaborn so that the graph looks cool.\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "## create the graph (you might not see it at this point, but you will after we save it as a PDF).\n",
    "sns.lineplot(x=input_doses, \n",
    "             y=output_values.detach(), ## NOTE: because final_bias has a gradident, we call detach() \n",
    "                                       ## to return a new tensor that only has the value and not the gradient.\n",
    "             color='green', \n",
    "             linewidth=2.5)\n",
    "\n",
    "## now label the y- and x-axes.\n",
    "plt.ylabel('Effectiveness')\n",
    "plt.xlabel('Dose')\n",
    "\n",
    "## lastly, save the graph as a PDF.\n",
    "#plt.savefig('BasicLightningTrain.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the training data for the neural network.\n",
    "# inputs = torch.tensor([0., 0.5, 1.])\n",
    "# labels = torch.tensor([0., 1., 0.])\n",
    "## NOTE: Because we have so little data, and let's be honest, it's an unrealistically small \n",
    "## amount of data, the learning rate algorithm, lr_find(), that we use in the next section has trouble. \n",
    "## So, the point here is to show how to use lr_find() when you have a reasonable amount of data, \n",
    "## which we fake here by making 100 copies of the inputs and labels.\n",
    "inputs = torch.tensor([0., 0.5, 1.] * 100)\n",
    "labels = torch.tensor([0., 1., 0.] * 100)\n",
    "\n",
    "## If we want to use Lightning for training, then we have to pass the Trainer the data wrapped in \n",
    "## something called a DataLoader. DataLoaders provide a handful of nice features including...\n",
    "##   1) They can access the data in minibatches instead of all at once. In other words,\n",
    "##      The DataLoader doesn't need us to load all of the data into memory first. Instead\n",
    "##      it just loads what it needs in an efficient way. This is crucial for large datasets.\n",
    "##   2) They can reshuffle the data every epoch to reduce model overfitting\n",
    "##   3) We can easily just use a fraction of the data if we want do a quick train\n",
    "dataset = TensorDataset(inputs, labels) \n",
    "dataloader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df12150-2da7-495a-b16d-a4f28813ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ecb132fcbf481b951b0bd0d7b173c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Restoring states from the checkpoint path at /Users/pouya/VS/time_series_pt/.lr_find_2d32b61e-543d-444e-9c44-fb2f4edd1fef.ckpt\n",
      "Restored all states from the checkpoint file at /Users/pouya/VS/time_series_pt/.lr_find_2d32b61e-543d-444e-9c44-fb2f4edd1fef.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_find() suggests 0.00214 for the learning rate.\n"
     ]
    }
   ],
   "source": [
    "model = BasicLightningTrain() # First, make model from the class\n",
    "\n",
    "## Now create a Trainer - we can use the trainer to...\n",
    "##  1) Find the optimal learning rate\n",
    "##  2) Train (optimize) the weights and biases in the model\n",
    "## By default, the trainer will run on your system's CPU\n",
    "trainer = L.Trainer(max_epochs=20) \n",
    "## However, if we wanted to automatically take advantage of any available GPUs,\n",
    "## we would set accelerator=\"auto\" to automatically use available GPUs\n",
    "## and we would set devices=\"auto\" to automatically select as many GPUs as we have.\n",
    "#\n",
    "# trainer = L.Trainer(max_epochs=34, accelerator=\"auto\", devices=\"auto\")\n",
    "\n",
    "## Now let's find the optimal learning rate\n",
    "lr_find_results = trainer.tuner.lr_find(model,\n",
    "                                        train_dataloaders=dataloader, # the training data\n",
    "                                        min_lr=0.001, # minimum learning rate\n",
    "                                        max_lr=1.0,   # maximum learning rate\n",
    "                                        early_stop_threshold=None) # setting this to \"None\" tests all 100 candidate rates\n",
    "new_lr = lr_find_results.suggestion() ## suggestion() returns the best guess for the optimal learning rate\n",
    "\n",
    "## now print out the learning rate\n",
    "print(f\"lr_find() suggests {new_lr:.5f} for the learning rate.\")\n",
    "\n",
    "# now set the model's learning rate to the new value\n",
    "model.learning_rate = new_lr\n",
    "\n",
    "## NOTE: we can also plot the loss for each learning rate tested.\n",
    "## When you have a lot of data, this graph can be useful\n",
    "## (see https://pytorch-lightning.readthedocs.io/en/1.4.5/advanced/lr_finder.html to learn how to interpret)\n",
    "## but when you only have 3 data points, like our example, this plot is pretty hard to interpret so I did\n",
    "## not cover it in the video.\n",
    "# fig = lr_finder.plot(suggest=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f0cd2-e79a-4b76-a852-3629fbdc4ce9",
   "metadata": {},
   "source": [
    "Now that we have an improved training rate, let's train the model to optimize `final_bias`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b031b-64d6-4b45-8bf4-f3f240a03071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "------------------------------\n",
      "1         Trainable params\n",
      "6         Non-trainable params\n",
      "7         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d4c56f93cb442099a55ecaea688f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Now that we have an improved learning rate, we can train the model (optimize final_bias)\n",
    "trainer.fit(model, train_dataloaders=dataloader)\n",
    "\n",
    "print(model.final_bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-settlement",
   "metadata": {},
   "source": [
    "So, if everything worked correctly, the optimizer should have converged on `final_bias = 16.0070`. **BAM!**\n",
    "\n",
    "Lastly, let's graph the output from the optimized neural network and see if it's the same as what we started with. If so, then the optimization worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-effects",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Dose')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## run the different doses through the neural network\n",
    "output_values = model(input_doses)\n",
    "\n",
    "## set the style for seaborn so that the graph looks cool.\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "## create the graph (you might not see it at this point, but you will after we save it as a PDF).\n",
    "sns.lineplot(x=input_doses, \n",
    "             y=output_values.detach(), ## NOTE: we call detach() because final_bias has a gradient\n",
    "             color='green', \n",
    "             linewidth=2.5)\n",
    "\n",
    "## now label the y- and x-axes.\n",
    "plt.ylabel('Effectiveness')\n",
    "plt.xlabel('Dose')\n",
    "\n",
    "## lastly, save the graph as a PDF.\n",
    "# plt.savefig('BasicLightningTrain_optimized.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3a4b7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m, devices\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator=\"mps\", devices=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e744717f27ba7160125fcc5ecfa9bd157c957b1c9fd950dbce749d0541d03f6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
